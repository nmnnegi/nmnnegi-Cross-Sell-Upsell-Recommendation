# ğŸ§  LangGraph Cross-Sell / Upsell Recommendation System

This project builds a modular LangGraph agent system that analyzes customer purchase data to generate personalized **cross-sell** and **upsell** recommendations, along with a detailed **natural language research report**. The data is stored in a **PostgreSQL** database hosted on **Render**.

---

## ğŸš€ Features

- Modular agent-based analysis using LangGraph
- Cross-sell & upsell recommendations based on:
  - Purchase patterns
  - Product affinity
  - Industry trends
- Clean and structured API via FastAPI
- Live research report generation in plain English
- **PostgreSQL** integration (hosted on Render â€“ Free Tier)

---

## ğŸ“‚ Project Structure

```
langgraph_crosssell/
ğŸ”¾ï¸ agents/                  # LangGraph sub-agents
ğŸ¢ customer_context.py
ğŸ¢ purchase_pattern.py
ğŸ¢ product_affinity.py
ğŸ¢ opportunity_scoring.py
ğŸ¢ report_generator.py
ğŸ“† db/                      # SQL schema and sample data
ğŸ¢ schema.sql
ğŸ¢ sample_data.sql
ğŸ¢ db_utils.py              # PostgreSQL connection and data fetch
ğŸ¢ graph_builder.py         # LangGraph pipeline
ğŸ¢ main.py                  # FastAPI API definition
ğŸ¢ requirements.txt
ğŸ¢ README.md                # You're here
```

---

## âš™ï¸ Installation

### 1. Clone the repository

```bash
git clone https://github.com/your-username/langgraph_crosssell.git
cd langgraph_crosssell
```

### 2. Set up a virtual environment

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ› ï¸ PostgreSQL Setup (via Render)

1. Go to [https://render.com](https://render.com) and sign in.
2. Create a new **PostgreSQL database** (Free Tier).
3. Go to your **Database Dashboard â†’ Connection Details**.
4. Run the schema and insert data via `psql` or Render's SQL Shell:
   - Upload and execute `db/schema.sql`
   - Then execute `db/sample_data.sql`
5. Update `db_utils.py` with your connection values:

```python
def get_connection():
    return psycopg2.connect(
        dbname="your_db",
        user="your_user",
        password="your_password",
        host="your_host",  # e.g., dpg-xyz.render.com
        port="5432"
    )
```

---

## â–¶ï¸ Run the API

```bash
uvicorn main:app --reload
```

Then open in your browser or Postman:

```
http://127.0.0.1:8000/recommendation?customer_id=C003
```

### ğŸ“… Sample Response

```json
{
  "customer_id": "C003",
  "report": "Cross-Sell and Upsell Opportunities for Pyramid Construction Inc.\n\nIndustry: Construction...",
  "recommendations": [
    {
      "product": "Backup Batteries",
      "score": 60,
      "rationale": "commonly purchased by peers"
    },
    {
      "product": "Safety Gear",
      "score": 40,
      "rationale": "frequently bought with existing products"
    }
  ]
}
```

---

## ğŸ“Œ Agents Summary

| Agent                   | Purpose                                                   |
| ----------------------- | --------------------------------------------------------- |
| CustomerContextAgent    | Extracts customer profile from PostgreSQL                 |
| PurchasePatternAgent    | Analyzes frequent vs missing purchases vs industry trends |
| ProductAffinityAgent    | Suggests co-purchased/related products                    |
| OpportunityScoringAgent | Scores opportunities based on synergy and relevance       |
| ReportGeneratorAgent    | Converts scores into a natural-language research report   |

---

## ğŸ’ª Example Customer IDs (from `sample_data.sql`)

- `C001` â€“ Edge Communications
- `C002` â€“ Burlington Textiles Corp
- `C003` â€“ Pyramid Construction Inc.
- `C004` â€“ Grand Hotels & Resorts
- `C005` â€“ United Oil & Gas Corp.

---

## âœ… TODO (Optional Enhancements)

- Add Dockerfile and PostgreSQL container
- Deploy FastAPI backend on Render or Railway
- Implement ML-based affinity prediction
- Add authentication layer

---

## ğŸ“„ License

MIT License â€“ free to use, modify, and distribute.

---

## ğŸ¤ Contributing

PRs and feedback welcome. Let's make B2B AI smarter together!
